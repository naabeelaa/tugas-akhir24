# -*- coding: utf-8 -*-
"""fixed prabowogibran svm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eCgZc1Sx8PVBV2gUhQRmEgGAHp9q9R99
"""

import pandas as pd
import re

df = pd.read_excel('prabowo gibran final.xlsx')
df.head()

"""#casefolding"""

df['casefolding'] = df['full_text'].str.lower()
df.head()

"""#cleaning data"""

def cleaning(text):
    text = re.sub(r'@', '', text)
    text = re.sub(r'#', '', text)
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    return text.strip()

df['cleaning'] = df['casefolding'].apply(cleaning)
df[['casefolding', 'cleaning']].head()

"""# tokenisasi"""

import nltk
nltk.download('punkt_tab')

import nltk
from nltk.tokenize import word_tokenize

nltk.download('punkt')
df['tokens'] = df['cleaning'].apply(word_tokenize)
df[['cleaning', 'tokens']].head()

df['tokens'] = df['cleaning'].apply(lambda x: x.split())
df[['cleaning', 'tokens']].head()

"""# stemming"""

from nltk.stem import PorterStemmer

stemmer = PorterStemmer()
df['stemmed_tokens'] = df['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])
df[['tokens', 'stemmed_tokens']].head()

"""#normalisasi"""

# List Manual
normalization_dict = {
    "jd": "jadi", "jgn": "jangan", "dgn": "dengan", "kira2": "kira kira", "spt": "seperti",
    "dlm": "dalam", "Mlm": "malam", "bgt": "banget", "udh": "udah", "utk": "untuk", "dah": "udah",
    "trs": "terus", "klo": "kalau", "emg": "emang", "mon": "mohon", "maap": "maaf", "gpp": "gapapa",
    "gmn": "gimana", "gegara": "gara gara", "ga": "nggak", "kaga": "tidak", "nga": "nggak",
    "ttg": "tentang", "pda": "pada", "skrng": "sekarang", "kyk": "kaya", "btw": "by the way",
    "yg": "yang", "dll": "dan lain lain", "emg": "emang", "utk": "untuk", "sm": "sama",
    "pd": "pada", "bkn": "bukan", "tp": "tapi", "tdk": "tidak", "sie": "sih", "mo": "mau",
    "kuatir": "khawatir", "kl": "kalau", "krn": "karena", "n": "dan", "ttp": "tetap", "bs": "bisa",
    "smg": "semoga", "lg": "lagi", "kel": "kelurahan", "kec": "kecamatan", "kab": "kabupaten",
    "prov": "provinsi", "bertg": "bertanggung", "jikalo": "jikalau", "ojo": "jangan", "belio": "beliau",
    "kp": "kampung", "klean": "kalian", "P.Diponegoro": "Pangeran Diponegoro", "klu": "kalau",
    "sy": "saya", "bgs": "bagus", "hrs": "harus", "sblm": "sebelum", "bnyk": "banyak", "cb": "coba",
    "sdh": "sudah", "br": "baru", "hrp": "harap", "bngt": "banget", "jend": "jenderal", "msh": "masih",
    "syny": "sayang", "dr": "dari", "jkw": "jokowi", "lg": "lagi", "Ig": "instagram", "kta": "kata",
    "sngking": "sangking", "aj": "aja", "orng": "orang", "nnti": "nanti", "wtk": "waktu",
    "gub": "gubernur", "ngmng": "ngomong", "ae": "aja", "makasih": "terimakasih", "ko": "kau",
    "gtu": "gitu", "sgtu": "segitu", "kdg": "kadang", "ane": "aku", "temlen": "timeline",
    "ultah": "ulang tahun", "dg": "dengan", "knp": "kenapa", "klah": "kalah", "mlwan": "melawan",
}

def normalize_tokens(tokens):
    return [normalization_dict.get(token, token) for token in tokens]

df['normalized_tokens'] = df['stemmed_tokens'].apply(normalize_tokens)
df[['stemmed_tokens', 'normalized_tokens']].head()

"""#stopword"""

!pip install Sastrawi

from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory

# Sastrawi
factory = StopWordRemoverFactory()
stopword_list = factory.get_stop_words()
stop_words = set(stopword_list)

def remove_stopwords(tokens):
    return [token for token in tokens if token not in stop_words]

df['filtered_tokens'] = df['normalized_tokens'].apply(remove_stopwords)
df[['normalized_tokens', 'filtered_tokens']].head()

df.to_excel('preprocessing.xlsx', index=False)

"""#TF-IDF"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

def tokens_to_string(tokens):
    return ' '.join(tokens)

def calculate_tfidf(df, token_column='filtered_tokens'):

    df['text_for_tfidf'] = df[token_column].apply(tokens_to_string)
    tfidf_vectorizer = TfidfVectorizer()
    tfidf_matrix = tfidf_vectorizer.fit_transform(df['text_for_tfidf'])

    feature_names = tfidf_vectorizer.get_feature_names_out()

    tfidf_df = pd.DataFrame(
        tfidf_matrix.toarray(),
        columns=feature_names
    )

    tfidf_df.index = df.index
    return tfidf_df, tfidf_vectorizer

def get_top_terms(tfidf_df, n_terms=10):
    """Get top terms by average TF-IDF score across all documents"""
    mean_tfidf = tfidf_df.mean()
    top_terms = mean_tfidf.sort_values(ascending=False).head(n_terms)
    return top_terms

def get_document_top_terms(tfidf_df, doc_index, n_terms=5):
    """Get top terms for a specific document"""
    doc_tfidf = tfidf_df.iloc[doc_index]
    top_terms = doc_tfidf.sort_values(ascending=False).head(n_terms)
    return top_terms

tfidf_df, vectorizer = calculate_tfidf(df)

top_terms = get_top_terms(tfidf_df, n_terms=10)
print("\nTop 10 terms across all documents:")
print(top_terms)

print("\nTop 5 terms in first document:")
print(get_document_top_terms(tfidf_df, 0))

tfidf_df.to_excel('tfidf_matrix.xlsx')

def create_summary_df(df, tfidf_df, n_terms=5):
    summaries = []
    for idx in range(len(df)):
        top_terms = get_document_top_terms(tfidf_df, idx, n_terms)
        summaries.append({
            'original_text': df['full_text'].iloc[idx],
            'top_terms': ', '.join(f"{term} ({score:.3f})" for term, score in top_terms.items())
        })
    return pd.DataFrame(summaries)

summary_df = create_summary_df(df, tfidf_df)
summary_df.to_excel('tfidf_summary.xlsx', index=False)

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

def tokens_to_string(tokens):
    return ' '.join(tokens)

def calculate_bag_of_words(df, token_column='filtered_tokens'):

    df['text_for_bow'] = df[token_column].apply(tokens_to_string)
    bow_vectorizer = CountVectorizer()
    bow_matrix = bow_vectorizer.fit_transform(df['text_for_bow'])
    feature_names = bow_vectorizer.get_feature_names_out()

    bow_df = pd.DataFrame(
        bow_matrix.toarray(),
        columns=feature_names
    )

    bow_df.index = df.index
    return bow_df, bow_vectorizer

def get_top_terms(bow_df, n_terms=10):

    total_counts = bow_df.sum()
    top_terms = total_counts.sort_values(ascending=False).head(n_terms)
    return top_terms

def get_document_top_terms(bow_df, doc_index, n_terms=5):

    doc_bow = bow_df.iloc[doc_index]
    top_terms = doc_bow.sort_values(ascending=False).head(n_terms)
    return top_terms

bow_df, vectorizer = calculate_bag_of_words(df)

top_terms = get_top_terms(bow_df, n_terms=10)
print("\nTop 10 terms across all documents:")
print(top_terms)

print("\nTop 5 terms in first document:")
print(get_document_top_terms(bow_df, 0))

bow_df.to_excel('bag_of_words_matrix.xlsx')

def create_summary_df(df, bow_df, n_terms=5):
    summaries = []
    for idx in range(len(df)):
        top_terms = get_document_top_terms(bow_df, idx, n_terms)
        summaries.append({
            'original_text': df['full_text'].iloc[idx],
            'top_terms': ', '.join(f"{term} ({count})" for term, count in top_terms.items())
        })
    return pd.DataFrame(summaries)

summary_df = create_summary_df(df, bow_df)
summary_df.to_excel('bag_of_words_summary.xlsx', index=False)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from scipy.sparse import csr_matrix

def tokens_to_string(tokens):
    return ' '.join(tokens)

df['text_for_vectorization'] = df['filtered_tokens'].apply(tokens_to_string)
def train_and_evaluate_svm(X, y, vectorizer, vectorizer_name):
    # Split 80:20
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    X_train_vectorized = vectorizer.fit_transform(X_train)
    X_test_vectorized = vectorizer.transform(X_test)

    svm_classifier = SVC(kernel='linear', random_state=42)
    svm_classifier.fit(X_train_vectorized, y_train)
    y_pred = svm_classifier.predict(X_test_vectorized)

    accuracy = accuracy_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    class_report = classification_report(y_test, y_pred)

    print(f"\nResults for {vectorizer_name}:")
    print(f"Accuracy: {accuracy:.4f}")
    print("\nClassification Report:")
    print(class_report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {vectorizer_name}')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

    return svm_classifier, vectorizer, accuracy

bow_vectorizer = CountVectorizer()
tfidf_vectorizer = TfidfVectorizer()

print("Training SVM with Bag of Words features...")
svm_bow, bow_vectorizer, bow_accuracy = train_and_evaluate_svm(
    df['text_for_vectorization'],
    df['Fix Label'],
    bow_vectorizer,
    "Bag of Words"
)

print("\nTraining SVM with TF-IDF features...")
svm_tfidf, tfidf_vectorizer, tfidf_accuracy = train_and_evaluate_svm(
    df['text_for_vectorization'],
    df['Fix Label'],
    tfidf_vectorizer,
    "TF-IDF"
)

print("\nComparison of Results:")
print(f"BOW Accuracy: {bow_accuracy:.4f}")
print(f"TF-IDF Accuracy: {tfidf_accuracy:.4f}")

def get_feature_importance(svm_model, vectorizer, n_top_features=10):
    feature_names = vectorizer.get_feature_names_out()

    if isinstance(svm_model.coef_, csr_matrix):
        coef = svm_model.coef_.toarray()[0]
    else:
        coef = svm_model.coef_[0]
    abs_coef = np.abs(coef)

    top_indices = np.argsort(abs_coef)[-n_top_features:][::-1]

    importance_df = pd.DataFrame({
        'Feature': feature_names[top_indices],
        'Importance': coef[top_indices]
    })

    return importance_df

bow_importance = get_feature_importance(svm_bow, bow_vectorizer)
tfidf_importance = get_feature_importance(svm_tfidf, tfidf_vectorizer)

print("\nTop Important Features (BOW):")
print(bow_importance)
print("\nTop Important Features (TF-IDF):")
print(tfidf_importance)

import joblib
joblib.dump(svm_bow, 'svm_bow_model.joblib')
joblib.dump(svm_tfidf, 'svm_tfidf_model.joblib')
joblib.dump(bow_vectorizer, 'bow_vectorizer.joblib')
joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')

bow_importance.to_csv('bow_feature_importance.csv', index=False)
tfidf_importance.to_csv('tfidf_feature_importance.csv', index=False)

def create_prediction_summary(df, X, y, svm_model, vectorizer, vectorizer_name):
    X_vectorized = vectorizer.transform(X)
    predictions = svm_model.predict(X_vectorized)

    summary_df = pd.DataFrame({
        'Original_Text': df['full_text'],
        'Preprocessed_Text': df['text_for_vectorization'],
        'True_Label': y,
        'Predicted_Label': predictions,
        'Correct_Prediction': y == predictions
    })

    summary_df.to_excel(f'prediction_summary_{vectorizer_name}.xlsx', index=False)

    return summary_df

bow_summary = create_prediction_summary(
    df,
    df['text_for_vectorization'],
    df['Fix Label'],
    svm_bow,
    bow_vectorizer,
    'BOW'
)

tfidf_summary = create_prediction_summary(
    df,
    df['text_for_vectorization'],
    df['Fix Label'],
    svm_tfidf,
    tfidf_vectorizer,
    'TFIDF'
)

from imblearn.over_sampling import SMOTE
from collections import Counter
import numpy as np

df['text_for_tfidf'] = df['filtered_tokens'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)

tfidf_vectorizer = TfidfVectorizer(max_features=1000)
X = tfidf_vectorizer.fit_transform(df['text_for_tfidf'])
y = df['Fix Label']

print("Original class distribution:")
print(Counter(y))

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("\nBalanced class distribution:")
print(Counter(y_resampled))

X_resampled_df = pd.DataFrame(
    X_resampled.toarray(),
    columns=tfidf_vectorizer.get_feature_names_out()
)

balanced_df = pd.DataFrame({
    'text': list(df['text_for_tfidf']) + [f"synthetic_sample_{i}" for i in range(len(y_resampled) - len(df))],
    'label': y_resampled,
    'is_synthetic': [0] * len(df) + [1] * (len(y_resampled) - len(df))
})

print("\nOriginal dataset shape:", X.shape)
print("Resampled dataset shape:", X_resampled.shape)

balanced_df.to_excel('balanced_dataset.xlsx', index=False)

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_curve,
    auc
)
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd


def create_complete_pipeline(df, feature_type='tfidf'):
    text_data = df['filtered_tokens'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)

    if feature_type == 'tfidf':
        vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.95
        )
    else:
        vectorizer = CountVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.95
        )

    X_features = vectorizer.fit_transform(text_data)

    scaler = StandardScaler(with_mean=False)
    X_scaled = scaler.fit_transform(X_features)

    k_best = SelectKBest(chi2, k=500)
    X_selected = k_best.fit_transform(X_scaled, df['Fix Label'])

    le = LabelEncoder()
    y_encoded = le.fit_transform(df['Fix Label'])

    X_train, X_test, y_train, y_test = train_test_split(
        X_selected, y_encoded,
        test_size=0.2,
        random_state=42,
        stratify=y_encoded
    )

    param_grid = {
        'C': [0.1, 1, 10, 100],
        'kernel': ['linear', 'rbf'],
        'gamma': ['scale', 'auto', 0.1, 0.01],
        'class_weight': ['balanced', None]
    }

    grid_search = GridSearchCV(
        SVC(probability=True, random_state=42),
        param_grid,
        cv=5,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )

    print(f"\nPerforming grid search for {feature_type.upper()}...")
    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)

    print(f"\nResults for {feature_type.upper()}:")
    print("Best parameters:", grid_search.best_params_)
    print(f"Best cross-validation score: {grid_search.best_score_:.4f}")

    y_test_original = le.inverse_transform(y_test)
    y_pred_original = le.inverse_transform(y_pred)

    print("\nClassification Report:")
    print(classification_report(y_test_original, y_pred_original))

    cm = confusion_matrix(y_test_original, y_pred_original)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=le.classes_,
                yticklabels=le.classes_)
    plt.title(f'Confusion Matrix ({feature_type.upper()})')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

    y_score = best_model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2,
             label=f'ROC curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curve ({feature_type.upper()})')
    plt.legend(loc="lower right")
    plt.show()

    return {
        'vectorizer': vectorizer,
        'scaler': scaler,
        'feature_selector': k_best,
        'model': best_model,
        'encoder': le,
        'accuracy': best_model.score(X_test, y_test),
        'best_params': grid_search.best_params_,
        'cv_score': grid_search.best_score_
    }

print("Starting TF-IDF pipeline...")
tfidf_results = create_complete_pipeline(df, feature_type='tfidf')

print("\nStarting BOW pipeline...")
bow_results = create_complete_pipeline(df, feature_type='bow')

comparison_df = pd.DataFrame({
    'Metric': ['Accuracy', 'CV Score'],
    'TF-IDF': [tfidf_results['accuracy'], tfidf_results['cv_score']],
    'BOW': [bow_results['accuracy'], bow_results['cv_score']]
})

print("\nComparison of TF-IDF and BOW results:")
print(comparison_df)